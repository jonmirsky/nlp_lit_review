TY  - JOUR
AB  - IMPORTANCE: Large language models (LLMs) have potential to increase the efficiency of information extraction from unstructured clinical notes in electronic medical records. OBJECTIVE: To assess the utility and reliability of an LLM, ChatGPT-4 (OpenAI), to analyze clinical narratives and identify helmet use status of patients injured in micromobility-related accidents. DESIGN, SETTING, AND PARTICIPANTS: This cross-sectional study used publicly available, deidentified 2019 to 2022 data from the US Consumer Product Safety Commission's National Electronic Injury Surveillance System, a nationally representative stratified probability sample of 96 hospitals in the US. Unweighted estimates of e-bike, bicycle, hoverboard, and powered scooter-related injuries that resulted in an emergency department visit were used. Statistical analysis was performed from November 2023 to April 2024. MAIN OUTCOMES AND MEASURES: Patient helmet status (wearing vs not wearing vs unknown) was extracted from clinical narratives using (1) a text string search using researcher-generated text strings and (2) the LLM by prompting the system with low-, intermediate-, and high-detail prompts. The level of agreement between the 2 approaches across all 3 prompts was analyzed using Cohen κ test statistics. Fleiss κ was calculated to measure the test-retest reliability of the high-detail prompt across 5 new chat sessions and days. Performance statistics were calculated by comparing results from the high-detail prompt to classifications of helmet status generated by researchers reading the clinical notes (ie, a criterion standard review). RESULTS: Among 54 569 clinical notes, moderate (Cohen κ = 0.74 [95% CI, 0.73-0.75) and weak (Cohen κ = 0.53 [95% CI, 0.52-0.54]) agreement were found between the text string-search approach and the LLM for the low- and intermediate-detail prompts, respectively. The high-detail prompt had almost perfect agreement (κ = 1.00 [95% CI, 1.00-1.00]) but required the greatest amount of time to complete. The LLM did not perfectly replicate its analyses across new sessions and days (Fleiss κ = 0.91 across 5 trials; P < .001). The LLM often hallucinated and was consistent in replicating its hallucinations. It also showed high validity compared with the criterion standard (n = 400; κ = 0.98 [95% CI, 0.96-1.00]). CONCLUSIONS AND RELEVANCE: This study's findings suggest that although there are efficiency gains for using the LLM to extract information from clinical notes, the inadequate reliability compared with a text string-search approach, hallucinations, and inconsistent performance significantly hinder the potential of the currently available LLM.
AU  - Burford, Kathryn G.
AU  - Itzkowitz, Nicole G.
AU  - Ortega, Ashley G.
AU  - Teitler, Julien O.
AU  - Rundle, Andrew G.
DA  - 2024 Aug 1
DO  - 10.1001/jamanetworkopen.2024.25981
IS  - 8
KW  - Humans
Reproducibility of Results
Female
Male
Middle Aged
Adult
Young Adult
Cross-Sectional Studies
Adolescent
United States/epidemiology
Electronic Health Records/statistics & numerical data
*Head Protective Devices/statistics & numerical data
Accidents, Traffic/statistics & numerical data
L1  - internal-pdf://11700/Burford et al. - 2024 - Use of Generative AI to Identify Helmet Status Among Patients With Micromobility-Related Injuries Fr.pdf
LA  - eng
LB  - 801
PY  - 2024
RN  - clinical, neurocritical_OR_"critical_care"_OR_triage_OR_emergency
SN  - 2574-3805
SP  - e2425981
ST  - Use of Generative AI to Identify Helmet Status Among Patients With Micromobility-Related Injuries From Unstructured Clinical Notes.
T2  - JAMA network open
TI  - Use of Generative AI to Identify Helmet Status Among Patients With Micromobility-Related Injuries From Unstructured Clinical Notes
VL  - 7
ID  - 27
ER  - 

TY  - JOUR
AB  - OBJECTIVE: To develop a natural language processing (NLP) algorithm that can accurately extract headache frequency from free-text clinical notes. BACKGROUND: Headache frequency, defined as the number of days with any headache in a month (or 4 weeks), remains a key parameter in the evaluation of treatment response to migraine preventive medications. However, due to the variations and inconsistencies in documentation by clinicians, significant challenges exist to accurately extract headache frequency from the electronic health record (EHR) by traditional NLP algorithms. METHODS: This was a retrospective cross-sectional study with patients identified from two tertiary headache referral centers, Mayo Clinic Arizona and Mayo Clinic Rochester. All neurology consultation notes written by 15 specialized clinicians (11 headache specialists and 4 nurse practitioners) between 2012 and 2022 were extracted and 1915 notes were used for model fine-tuning (90%) and testing (10%). We employed four different NLP frameworks: (1) ClinicalBERT (Bidirectional Encoder Representations from Transformers) regression model, (2) Generative Pre-Trained Transformer-2 (GPT-2) Question Answering (QA) model zero-shot, (3) GPT-2 QA model few-shot training fine-tuned on clinical notes, and (4) GPT-2 generative model few-shot training fine-tuned on clinical notes to generate the answer by considering the context of included text. RESULTS: The mean (standard deviation) headache frequency of our training and testing datasets were 13.4 (10.9) and 14.4 (11.2), respectively. The GPT-2 generative model was the best-performing model with an accuracy of 0.92 (0.91, 0.93, 95% confidence interval [CI]) and R(2) score of 0.89 (0.87, 0.90, 95% CI), and all GPT-2-based models outperformed the ClinicalBERT model in terms of exact matching accuracy. Although the ClinicalBERT regression model had the lowest accuracy of 0.27 (0.26, 0.28), it demonstrated a high R(2) score of 0.88 (0.85, 0.89), suggesting the ClinicalBERT model can reasonably predict the headache frequency within a range of ≤ ± 3 days, and the R(2) score was higher than the GPT-2 QA zero-shot model or GPT-2 QA model few-shot training fine-tuned model. CONCLUSION: We developed a robust information extraction model based on a state-of-the-art large language model, a GPT-2 generative model that can extract headache frequency from EHR free-text clinical notes with high accuracy and R(2) score. It overcame several challenges related to different ways clinicians document headache frequency that were not easily achieved by traditional NLP models. We also showed that GPT-2-based frameworks outperformed ClinicalBERT in terms of accuracy in extracting headache frequency from clinical notes. To facilitate research in the field, we released the GPT-2 generative model and inference code with open-source license of community use in GitHub. Additional fine-tuning of the algorithm might be required when applied to different health-care systems for various clinical use cases.
AU  - Chiang, Chia-Chun
AU  - Luo, Man
AU  - Dumkrieger, Gina
AU  - Trivedi, Shubham
AU  - Chen, Yi-Chieh
AU  - Chao, Chieh-Ju
AU  - Schwedt, Todd J.
AU  - Sarker, Abeed
AU  - Banerjee, Imon
DA  - 2024 Apr
DO  - 10.1111/head.14702
IS  - 4
KW  - artificial intelligence
natural language processing
Humans
large language model
Retrospective Studies
*Natural Language Processing
Female
Male
Middle Aged
Adult
*Electronic Health Records
Algorithms
Cross-Sectional Studies
migraine
Headache
headache frequency
L1  - internal-pdf://0304089171/Chiang-2024-A large language model-based gener.pdf
LA  - eng
LB  - 2525
PY  - 2024
RN  - clinical, neurology
SN  - 1526-4610 0017-8748
SP  - 400–409
ST  - A large language model-based generative natural language processing framework fine-tuned on clinical notes accurately extracts headache frequency from electronic health records.
T2  - Headache
TI  - A large language model-based generative natural language processing framework fine-tuned on clinical notes accurately extracts headache frequency from electronic health records
UR  - https://headachejournal.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/head.14702?download=true
VL  - 64
ID  - 14
ER  - 

TY  - JOUR
AB  - BACKGROUND: Injuries pose a significant global health challenge due to their high incidence and mortality rates. Although injury surveillance is essential for prevention, it is resource-intensive. This study aimed to develop and validate locally deployable large language models (LLMs) to extract core injury-related information from Emergency Department (ED) clinical notes. METHODS: We conducted a diagnostic study using retrospectively collected data from January 2014 to December 2020 from two urban academic tertiary hospitals. One served as the derivation cohort and the other as the external test cohort. Adult patients presenting to the ED with injury-related complaints were included. Primary outcomes included classification accuracies for information extraction tasks related to injury mechanism, place of occurrence, activity, intent, and severity. We fine-tuned a single generalizable Llama-2 model and five distinct Bidirectional Encoder Representations from Transformers (BERT) models for each task to extract information from initial ED physician notes. The Llama-2 model was able to perform different tasks by modifying the instruction prompt. Data recorded in injury registries provided the gold standard labels. Model performance was assessed using accuracy and macro-average F1 scores. RESULTS: The derivation and external test cohorts comprised 36,346 and 32,232 patients, respectively. In the derivation cohort's test set, the Llama-2 model achieved accuracies (95% confidence intervals) of 0.899 (0.889-0.909) for injury mechanism, 0.774 (0.760-0.789) for place of occurrence, 0.679 (0.665-0.694) for activity, 0.972 (0.967-0.977) for intent, and 0.935 (0.926-0.943) for severity. The Llama-2 model outperformed the BERT models in accuracy and macro-average F1 scores across all tasks in both cohorts. Imposing constraints on the Llama-2 model to avoid uncertain predictions further improved its accuracy. CONCLUSION: Locally deployable LLMs, trained to extract core injury-related information from free-text ED clinical notes, demonstrated good performance. Generative LLMs can serve as versatile solutions for various injury-related information extraction tasks.
AU  - Choi, Dong Hyun
AU  - Kim, Yoonjic
AU  - Choi, Sae Won
AU  - Kim, Ki Hong
AU  - Choi, Yeongho
AU  - Shin, Sang Do
DA  - 2024 Dec 2
DO  - 10.3346/jkms.2024.39.e291
IS  - 46
KW  - Humans
Retrospective Studies
Female
Male
Middle Aged
Adult
Aged
Electronic Health Records
*Emergency Service, Hospital
Tertiary Care Centers
Information Extraction
Large Language Model
*Wounds and Injuries
Clinical Note
Emergency Department
Injuries
L1  - internal-pdf://11734/Choi et al. - 2024 - Using Large Language Models to Extract Core Injury Information From Emergency Department Notes..pdf
LA  - eng
LB  - 831
PY  - 2024
RN  - clinical, neurocritical_OR_"critical_care"_OR_triage_OR_emergency
SN  - 1598-6357 1011-8934
SP  - e291
ST  - Using Large Language Models to Extract Core Injury Information From Emergency Department Notes.
T2  - Journal of Korean medical science
TI  - Using Large Language Models to Extract Core Injury Information From Emergency Department Notes
VL  - 39
ID  - 26
ER  - 

TY  - JOUR
AB  - BACKGROUND: Overcrowding in emergency departments (EDs) leads to delayed treatments, poor patient outcomes, and increased staff workloads. Artificial intelligence (AI) and machine learning (ML) have emerged as promising tools to optimize triage. OBJECTIVE: This systematic review evaluates AI/ML-driven triage and risk stratification models in EDs, focusing on predictive performance, key predictors, clinical and operational outcomes, and implementation challenges. METHODS: Following PRISMA 2020 guidelines, we systematically searched PubMed, CINAHL, Scopus, Web of Science, and IEEE Xplore for studies on AI/ML-driven ED triage published through January 2025. Two independent reviewers screened studies, extracted data, and assessed quality using PROBAST, with findings synthesized thematically. RESULTS: Twenty-six studies met inclusion criteria. ML-based triage models consistently outperformed traditional tools, often achieving AUCs > 0.80 for high acuity outcomes (e.g., hospital admission, ICU transfer). Key predictors included vital signs, age, arrival mode, and disease-specific markers. Incorporating free-text data via natural language processing enhances accuracy and sensitivity. Advanced ML techniques, such as gradient boosting and random forests, generally surpassed simpler models across diverse populations. Reported benefits included reduced ED overcrowding, improved resource allocation, fewer mis-triaged patients, and potential patient outcome improvements. CONCLUSION: AI/ML-based triage models hold substantial promise in improving ED efficiency and patient outcomes. Prospective, multi-center trials with transparent reporting and seamless electronic health record integration are essential to confirm these benefits. IMPLICATIONS FOR CLINICAL PRACTICE: Integrating AI and ML into ED triage can enhance assessment accuracy and resource allocation. Early identification of high-risk patients supports better clinical decision-making, including critical care and ICU nurses, by streamlining patient transitions and reducing overcrowding. Explainable AI models foster trust and enable informed decisions under pressure. To realize these benefits, healthcare organizations must invest in robust infrastructure, provide comprehensive training for all clinical staff, and implement ethical, standardized practices that support interdisciplinary collaboration between ED and ICU teams.
AU  - El Arab, Rabie Adel
AU  - Al Moosa, Omayma Abdulaziz
DA  - 2025 Aug
DO  - 10.1016/j.iccn.2025.104058
KW  - Artificial intelligence Humans Machine learning Natural language processing Clinical decision support Machine Learning Risk stratification Predictive modeling *Artificial Intelligence/trends/standards *Triage/methods/standards/trends Emergency departmen
L1  - internal-pdf://2229656756/The role of AI in emergency depar-El Arab-2025.pdf
LA  - eng
LB  - 3217
N1  - clinical
PY  - 2025
RN  - clinical
SN  - 1532-4036 0964-3397
SP  - 104058
ST  - The role of AI in emergency department triage: An integrative systematic review. T2 - Intensive & critical care nursing
TI  - The role of AI in emergency department triage: An integrative systematic review
UR  - https://www.sciencedirect.com/science/article/abs/pii/S0964339725001193?via%3Dihub
VL  - 89
ID  - 4
ER  - 

TY  - JOUR
AB  - Background The latest large language models (LLMs) solve unseen problems via user-defined text prompts without the need for retraining, offering potentially more efficient information extraction from free-text medical records than manual annotation. Purpose To compare the performance of the LLMs ChatGPT and GPT-4 in data mining and labeling oncologic phenotypes from free-text CT reports on lung cancer by using user-defined prompts. Materials and Methods This retrospective study included patients who underwent lung cancer follow-up CT between September 2021 and March 2023. A subset of 25 reports was reserved for prompt engineering to instruct the LLMs in extracting lesion diameters, labeling metastatic disease, and assessing oncologic progression. This output was fed into a rule-based natural language processing pipeline to match ground truth annotations from four radiologists and derive performance metrics. The oncologic reasoning of LLMs was rated on a five-point Likert scale for factual correctness and accuracy. The occurrence of confabulations was recorded. Statistical analyses included Wilcoxon signed rank and McNemar tests. Results On 424 CT reports from 424 patients (mean age, 65 years ± 11 [SD]; 265 male), GPT-4 outperformed ChatGPT in extracting lesion parameters (98.6% vs 84.0%, P < .001), resulting in 96% correctly mined reports (vs 67% for ChatGPT, P < .001). GPT-4 achieved higher accuracy in identification of metastatic disease (98.1% [95% CI: 97.7, 98.5] vs 90.3% [95% CI: 89.4, 91.0]) and higher performance in generating correct labels for oncologic progression (F1 score, 0.96 [95% CI: 0.94, 0.98] vs 0.91 [95% CI: 0.89, 0.94]) (both P < .001). In oncologic reasoning, GPT-4 had higher Likert scale scores for factual correctness (4.3 vs 3.9) and accuracy (4.4 vs 3.3), with a lower rate of confabulation (1.7% vs 13.7%) than ChatGPT (all P < .001). Conclusion When using user-defined prompts, GPT-4 outperformed ChatGPT in extracting oncologic phenotypes from free-text CT reports on lung cancer and demonstrated better oncologic reasoning with fewer confabulations. © RSNA, 2023 Supplemental material is available for this article. See also the editorial by Hafezi-Nejad and Trivedi in this issue.
AU  - Fink, Matthias A.
AU  - Bischoff, Arved
AU  - Fink, Christoph A.
AU  - Moll, Martin
AU  - Kroschke, Jonas
AU  - Dulz, Luca
AU  - Heußel, Claus Peter
AU  - Kauczor, Hans-Ulrich
AU  - Weber, Tim F.
DA  - 2023/09//undefined
DO  - 10.1148/radiol.231362
IS  - 3
J2  - Radiology
KW  - Humans
Retrospective Studies
Male
Aged
*Lung Neoplasms/diagnostic imaging
Data Mining
Medical Oncology
Benchmarking
*Neoplasms, Second Primary
Memory Disorders
L1  - internal-pdf://0481928577/Potential of ChatGPT and GPT-4 for D-Fink-2023.pdf
LA  - eng
LB  - 2590
PY  - 2023
RN  - CT, CT_extraction
SN  - 1527-1315 0033-8419
SP  - e231362
ST  - Potential of ChatGPT and GPT-4 for Data Mining of Free-Text CT Reports on Lung Cancer
T2  - Radiology
TI  - Potential of ChatGPT and GPT-4 for Data Mining of Free-Text CT Reports on Lung Cancer
VL  - 308
ID  - 20
ER  - 

TY  - JOUR
AB  - INTRODUCTION: Electronic health records contain an enormous amount of valuable information recorded in free text. Information extraction is the strategy to transform free text into structured data, but some of its components require annotated data to tune, which has become a bottleneck. Large language models achieve good performances on various downstream NLP tasks without parameter tuning, becoming a possible way to extract information in a zero-shot manner. METHODS: In this study, we aim to explore whether the most popular large language model, ChatGPT, can extract information from the radiological reports. We first design the prompt template for the interested information in the CT reports. Then, we generate the prompts by combining the prompt template with the CT reports as the inputs of ChatGPT to obtain the responses. A post-processing module is developed to transform the responses into structured extraction results. Besides, we add prior medical knowledge to the prompt template to reduce wrong extraction results. We also explore the consistency of the extraction results. RESULTS: We conducted the experiments with 847 real CT reports. The experimental results indicate that ChatGPT can achieve competitive performances for some extraction tasks like tumor location, tumor long and short diameters compared with the baseline information extraction system. By adding some prior medical knowledge to the prompt template, extraction tasks about tumor spiculations and lobulations obtain significant improvements but tasks about tumor density and lymph node status do not achieve better performances. CONCLUSION: ChatGPT can achieve competitive information extraction for radiological reports in a zero-shot manner. Adding prior medical knowledge as instructions can further improve performances for some extraction tasks but may lead to worse performances for some complex extraction tasks.
AU  - Hu, Danqing
AU  - Liu, Bing
AU  - Zhu, Xiaofeng
AU  - Lu, Xudong
AU  - Wu, Nan
DA  - 2024/03//undefined
DO  - 10.1016/j.ijmedinf.2023.105321
J2  - Int J Med Inform
KW  - Humans
Large language model
Information extraction
Language
Radiological report
*Electronic Health Records
Information Storage and Retrieval
Question answering
*Neoplasms
Lung cancer
Knowledge
L1  - internal-pdf://1088590930/Zero-shot information extraction from-Hu-2024.pdf
LA  - eng
LB  - 2759
PY  - 2024
RN  - CT, CT_extraction
SN  - 1872-8243 1386-5056
SP  - 105321
ST  - Zero-shot information extraction from radiological reports using ChatGPT
T2  - International journal of medical informatics
TI  - Zero-shot information extraction from radiological reports using ChatGPT
VL  - 183
ID  - 21
ER  - 

TY  - JOUR
AB  - Biomedical research underpins progress in our understanding of human health and disease, drug discovery, and clinical care. However, with the growth of complex lab experiments, large datasets, many analytical tools, and expansive literature, biomedical research is increasingly constrained by repetitive and fragmented workflows that slow discovery and limit innovation, underscoring the need for a fundamentally new way to scale scientific expertise. Here, we introduce Biomni, a general-purpose biomedical AI agent designed to autonomously execute a wide spectrum of research tasks across diverse biomedical subfields. To systematically map the biomedical action space, Biomni first employs an action discovery agent to create the first unified agentic environment - mining essential tools, databases, and protocols from tens of thousands of publications across 25 biomedical domains. Built on this foundation, Biomni features a generalist agentic architecture that integrates large language model (LLM) reasoning with retrieval-augmented planning and code-based execution, enabling it to dynamically compose and carry out complex biomedical workflows - entirely without relying on predefined templates or rigid task flows. Systematic benchmarking demonstrates that Biomni achieves strong generalization across heterogeneous biomedical tasks - including causal gene prioritization, drug repurposing, rare disease diagnosis, microbiome analysis, and molecular cloning - without any task-specific prompt tuning. Real-world case studies further showcase Biomni's ability to interpret complex, multi-modal biomedical datasets and autonomously generate experimentally testable protocols. Biomni envisions a future where virtual AI biologists operate alongside and augment human scientists to dramatically enhance research productivity, clinical insight, and healthcare. Biomni is ready to use at https://biomni.stanford.edu, and we invite scientists to explore its capabilities, stress-test its limits, and co-create the next era of biomedical discoveries.
AU  - Huang, Kexin
AU  - Zhang, Serena
AU  - Wang, Hanchen
AU  - Qu, Yuanhao
AU  - Lu, Yingzhou
AU  - Roohani, Yusuf
AU  - Li, Ryan
AU  - Qiu, Lin
AU  - Li, Gavin
AU  - Zhang, Junze
AU  - Yin, Di
AU  - Marwaha, Shruti
AU  - Carter, Jennefer N.
AU  - Zhou, Xin
AU  - Wheeler, Matthew
AU  - Bernstein, Jonathan A.
AU  - Wang, Mengdi
AU  - He, Peng
AU  - Zhou, Jingtian
AU  - Snyder, Michael
AU  - Cong, Le
AU  - Regev, Aviv
AU  - Leskovec, Jure
DA  - 2025 Jun 2
DO  - 10.1101/2025.05.30.656746
L1  - internal-pdf://11890/Huang et al. - 2025 - Biomni A General-Purpose Biomedical AI Agent..pdf
LA  - eng
LB  - 962
PY  - 2025
RN  - clinical
ST  - Biomni: A General-Purpose Biomedical AI Agent.
TI  - Biomni: A General-Purpose Biomedical AI Agent
ID  - 6
ER  - 

TY  - JOUR
AB  - Artificial intelligence (AI) in healthcare is the ability of a computer to perform tasks typically associated with clinical care (e.g. medical decision-making and documentation). AI will soon be integrated into an increasing number of healthcare applications, including elements of emergency department (ED) care. Here, we describe the basics of AI, various categories of its functions (including machine learning and natural language processing) and review emerging and potential future use-cases for emergency care. For example, AI-assisted symptom checkers could help direct patients to the appropriate setting, models could assist in assigning triage levels, and ambient AI systems could document clinical encounters. AI could also help provide focused summaries of charts, summarize encounters for hand-offs, and create discharge instructions with an appropriate language and reading level. Additional use cases include medical decision making for decision rules, real-time models that predict clinical deterioration or sepsis, and efficient extraction of unstructured data for coding, billing, research, and quality initiatives. We discuss the potential transformative benefits of AI, as well as the concerns regarding its use (e.g. privacy, data accuracy, and the potential for changing the doctor-patient relationship).
AU  - Kachman, Marika M.
AU  - Brennan, Irina
AU  - Oskvarek, Jonathan J.
AU  - Waseem, Tayab
AU  - Pines, Jesse M.
DA  - 2024 Jul
DO  - 10.1016/j.ajem.2024.04.024
KW  - *Artificial Intelligence Artificial intelligence Humans Machine learning Natural Language Processing Machine Learning Technology Triage/methods Emergency department Clinical Decision-Making/methods Emergency Medical Services/methods Emergency medicine E
L1  - internal-pdf://2273885593/How artificial intelligence could-Kachman-2024.pdf
LA  - eng
LB  - 3238
N1  - clinical
PY  - 2024
RN  - clinical, neurocritical_OR_"critical_care"_OR_triage_OR_emergency
SN  - 1532-8171 0735-6757
SP  - 40–46
ST  - How artificial intelligence could transform emergency care. T2 - The American journal of emergency medicine
TI  - How artificial intelligence could transform emergency care
VL  - 81
ID  - 33
ER  - 

TY  - JOUR
AB  - BACKGROUND: Artificial intelligence (AI) technologies, such as machine learning and natural language processing, have the potential to provide new insights into complex health data. Although powerful, these algorithms rarely move from experimental studies to direct clinical care implementation. OBJECTIVE: We aimed to describe the key components for successful development and integration of two AI technology-based research pipelines for clinical practice. METHODS: We summarized the approach, results, and key learnings from the implementation of the following two systems implemented at a large, tertiary care children's hospital: (1) epilepsy surgical candidate identification (or epilepsy ID) in an ambulatory neurology clinic; and (2) an automated clinical trial eligibility screener (ACTES) for the real-time identification of patients for research studies in a pediatric emergency department. RESULTS: The epilepsy ID system performed as well as board-certified neurologists in identifying surgical candidates (with a sensitivity of 71% and positive predictive value of 77%). The ACTES system decreased coordinator screening time by 12.9%. The success of each project was largely dependent upon the collaboration between machine learning experts, research and operational information technology professionals, longitudinal support from clinical providers, and institutional leadership. CONCLUSIONS: These projects showcase novel interactions between machine learning recommendations and providers during clinical care. Our deployment provides seamless, real-time integration of AI technology to provide decision support and improve patient care.
AU  - Kanbar, Lara J.
AU  - Wissel, Benjamin
AU  - Ni, Yizhao
AU  - Pajor, Nathan
AU  - Glauser, Tracy
AU  - Pestian, John
AU  - Dexheimer, Judith W.
DA  - 2022 Dec 16
DO  - 10.2196/37833
IS  - 12
KW  - artificial intelligence
natural language processing
machine learning
electronic health record
clinical decision support
emergency medicine
epilepsy
L1  - internal-pdf://12646/Kanbar et al. - 2022 - Implementation of Machine Learning Pipelines for Clinical Practice Development and Validation Study.pdf
LA  - eng
LB  - 1631
PY  - 2022
RN  - clinical, neurology
SN  - 2291-9694
SP  - e37833
ST  - Implementation of Machine Learning Pipelines for Clinical Practice: Development and Validation Study.
T2  - JMIR medical informatics
TI  - Implementation of Machine Learning Pipelines for Clinical Practice: Development and Validation Study
VL  - 10
ID  - 15
ER  - 

TY  - JOUR
AB  - Purpose To assess the performance of a local open-source large language model (LLM) in various information extraction tasks from real-life emergency brain MRI reports. Materials and Methods All consecutive emergency brain MRI reports written in 2022 from a French quaternary center were retrospectively reviewed. Two radiologists identified MRI scans that were performed in the emergency department for headaches. Four radiologists scored the reports' conclusions as either normal or abnormal. Abnormalities were labeled as either headache-causing or incidental. Vicuna (LMSYS Org), an open-source LLM, performed the same tasks. Vicuna's performance metrics were evaluated using the radiologists' consensus as the reference standard. Results Among the 2398 reports during the study period, radiologists identified 595 that included headaches in the indication (median age of patients, 35 years [IQR, 26-51 years]; 68% [403 of 595] women). A positive finding was reported in 227 of 595 (38%) cases, 136 of which could explain the headache. The LLM had a sensitivity of 98.0% (95% CI: 96.5, 99.0) and specificity of 99.3% (95% CI: 98.8, 99.7) for detecting the presence of headache in the clinical context, a sensitivity of 99.4% (95% CI: 98.3, 99.9) and specificity of 98.6% (95% CI: 92.2, 100.0) for the use of contrast medium injection, a sensitivity of 96.0% (95% CI: 92.5, 98.2) and specificity of 98.9% (95% CI: 97.2, 99.7) for study categorization as either normal or abnormal, and a sensitivity of 88.2% (95% CI: 81.6, 93.1) and specificity of 73% (95% CI: 62, 81) for causal inference between MRI findings and headache. Conclusion An open-source LLM was able to extract information from free-text radiology reports with excellent accuracy without requiring further training. Keywords: Large Language Model (LLM), Generative Pretrained Transformers (GPT), Open Source, Information Extraction, Report, Brain, MRI Supplemental material is available for this article. Published under a CC BY 4.0 license. See also the commentary by Akinci D'Antonoli and Bluethgen in this issue.
AU  - Le Guellec, Bastien
AU  - Lefèvre, Alexandre
AU  - Geay, Charlotte
AU  - Shorten, Lucas
AU  - Bruge, Cyril
AU  - Hacein-Bey, Lotfi
AU  - Amouyel, Philippe
AU  - Pruvo, Jean-Pierre
AU  - Kuchcinski, Gregory
AU  - Hamroun, Aghiles
DA  - 2024 Jul
DO  - 10.1148/ryai.230364
IS  - 4
KW  - Humans
Retrospective Studies
*Natural Language Processing
Female
Male
Middle Aged
MRI
Sensitivity and Specificity
*Magnetic Resonance Imaging/methods
Adult
Brain
Report
Information Extraction
*Headache/diagnostic imaging/diagnosis
Brain/diagnostic imaging/pathology
Emergency Service, Hospital
Generative Pretrained Transformers (GPT)
Large Language Model (LLM)
Open Source
L1  - internal-pdf://13268/Le Guellec et al. - 2024 - Performance of an Open-Source Large Language Model in Extracting Information from Free-Text Radiolog.pdf
LA  - eng
LB  - 2180
PY  - 2024
RN  - brain, clinical, radiology
SN  - 2638-6100
SP  - e230364
ST  - Performance of an Open-Source Large Language Model in Extracting Information from Free-Text Radiology Reports.
T2  - Radiology. Artificial intelligence
TI  - Performance of an Open-Source Large Language Model in Extracting Information from Free-Text Radiology Reports
VL  - 6
ID  - 2
ER  - 

TY  - JOUR
AB  - Despite major advances in artificial intelligence (AI) research for healthcare, the deployment and adoption of AI technologies remain limited in clinical practice. This paper describes the FUTURE-AI framework, which provides guidance for the development and deployment of trustworthy AI tools in healthcare. The FUTURE-AI Consortium was founded in 2021 and comprises 117 interdisciplinary experts from 50 countries representing all continents, including AI scientists, clinical researchers, biomedical ethicists, and social scientists. Over a two year period, the FUTURE-AI guideline was established through consensus based on six guiding principles-fairness, universality, traceability, usability, robustness, and explainability. To operationalise trustworthy AI in healthcare, a set of 30 best practices were defined, addressing technical, clinical, socioethical, and legal dimensions. The recommendations cover the entire lifecycle of healthcare AI, from design, development, and validation to regulation, deployment, and monitoring.
AD  - Artificial Intelligence in Medicine Lab (BCN-AIM), Departament de Matematiques i Informatica, Universitat de Barcelona, Barcelona, Spain. Institucio Catalana de Recerca i Estudis Avancats (ICREA), Barcelona, Spain. Center for Computational Imaging & Simulation Technologies in Biomedicine, Schools of Computing and Medicine, University of Leeds, Leeds, UK. Medical Imaging Research Centre (MIRC), Cardiovascular Science and Electronic Engineering Departments, KU Leuven, Leuven, Belgium. Department of Biostatistics and Informatics, Colorado School of Public Health, University of Colorado Anschutz Medical Campus, Aurora, CO, USA. Department of Computing, Imperial College London, London, UK. IBM Research Africa, Nairobi, Kenya. Departments of Radiology, Medicine, and Biomedical Data Science, Stanford University School of Medicine, Stanford, CA, USA. Fraunhofer Heinrich Hertz Institute, Berlin, Germany. Amsterdam University Medical Centers, Department of Cardiology, University of Amsterdam, Amsterdam, Netherlands. Health Data Research UK and Institute of Health Informatics, University College London, London, UK. Department of Biomedical Informatics, University of Arkansas for Medical Sciences, Little Rock, AR, USA. Centre for Statistics in Medicine, University of Oxford, Oxford, UK. Institute for AI and Informatics in Medicine, Klinikum rechts der Isar, Technical University Munich, Munich, Germany. Gruppo Maggioli, Research and Development Lab, Athens, Greece. Institut Curie, Inserm, Orsay, France. Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA. Department of Radiology and Biomedical Imaging, University of California San Francisco, San Francisco, CA, USA. Institute of Machine Learning in Biomedical Imaging, Helmholtz Center Munich, Munich, Germany. Department of Radiation Sciences, Diagnostic Radiology, Umea University, Umea, Sweden. Foundation for Research and Technology-Hellas (FORTH), Crete, Greece. Department of Software Engineering, Namibia University of Science & Technology, Windhoek, Namibia. Centre for Genomic Regulation, Barcelona Institute of Science and Technology, Barcelona, Spain. Division of Intelligent Medical Systems, German Cancer Research Centre, Heidelberg, Germany. Biomedical Imaging Research Group, La Fe Health Research Institute, Valencia, Spain. Medical Imaging Department, Hospital Universitario y Politecnico La Fe, Valencia, Spain. School of Biomedical Engineering & Imaging Sciences, King's College London, London, UK. 2nd Division of Radiology, Medical University of Gdansk, Gdansk, Poland. Faculty of Law and Criminology, Ghent University, Ghent, Belgium. Data Science Department, EURECOM, Sophia Antipolis, France. Institute of History and Ethics in Medicine, Technical University of Munich, Munich, Germany. Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Hospital, Washington DC, USA. Department of Radiology & Nuclear Medicine, Erasmus MC University Medical Centre, Rotterdam, Netherlands. Copenhagen Academy for Medical Education and Simulation Rigshospitalet, University of Copenhagen, Copenhagen, Denmark. BBMRI-ERIC, ELSI Services & Research, Graz, Austria. Computational Clinical Imaging Group, Champalimaud Foundation, Lisbon, Portugal. Integrative Biomedical Imaging Informatics at Stanford (IBIIS), Department of Radiology, Stanford University, Stanford, CA, USA. Institute of Information Science and Technologies of the National Research Council of Italy, Pisa, Italy. Artificial Intelligence in Healthcare Program, TIC Salut Social Foundation, Barcelona, Spain. Department of Philosophy, and School of Medicine, Macquarie University, Sydney, Australia. The D-lab, Department of Precision Medicine, GROW-School for Oncology and Reproduction, Maastricht University, Maastricht, Netherlands.
AN  - 39909534
AU  - Lekadir, K.
AU  - Frangi, A. F.
AU  - Porras, A. R.
AU  - Glocker, B.
AU  - Cintas, C.
AU  - Langlotz, C. P.
AU  - Weicken, E.
AU  - Asselbergs, F. W.
AU  - Prior, F.
AU  - Collins, G. S.
AU  - Kaissis, G.
AU  - Tsakou, G.
AU  - Buvat, I.
AU  - Kalpathy-Cramer, J.
AU  - Mongan, J.
AU  - Schnabel, J. A.
AU  - Kushibar, K.
AU  - Riklund, K.
AU  - Marias, K.
AU  - Amugongo, L. M.
AU  - Fromont, L. A.
AU  - Maier-Hein, L.
AU  - Cerda-Alberich, L.
AU  - Marti-Bonmati, L.
AU  - Cardoso, M. J.
AU  - Bobowicz, M.
AU  - Shabani, M.
AU  - Tsiknakis, M.
AU  - Zuluaga, M. A.
AU  - Fritzsche, M. C.
AU  - Camacho, M.
AU  - Linguraru, M. G.
AU  - Wenzel, M.
AU  - De Bruijne, M.
AU  - Tolsgaard, M. G.
AU  - Goisauf, M.
AU  - Cano Abadia, M.
AU  - Papanikolaou, N.
AU  - Lazrak, N.
AU  - Pujol, O.
AU  - Osuala, R.
AU  - Napel, S.
AU  - Colantonio, S.
AU  - Joshi, S.
AU  - Klein, S.
AU  - Ausso, S.
AU  - Rogers, W. A.
AU  - Salahuddin, Z.
AU  - Starmans, M. P. A.
AU  - Consortium, Future-Ai
C1  - Competing interests: All authors have completed the ICMJE uniform disclosure form at www.icmje.org/disclosure-of-interest/ and declare: support from European Union's Horizon 2020 for the submitted work; no financial relationships with any organisations that might have an interest in the submitted work in the previous three years; no other relationships or activities that could appear to have influenced the submitted work. GD owns equity interest in Artrya Ltd and provides consultancy services. JK-C receives research funding from GE, Genetech and is a consultant at Siloam Vision. GPK advises some AI startups such as Gleamer.AI, FLUIDDA BV, NanoX Vision and was the founder of Quantib BV. SEP is a consultant for Circle Cardiovascular Imaging, Calgary, Alberta, Canada. BG is employed by Kheiron Medical Technologies and HeartFlow. PL has/had grants/sponsored research agreements from Radiomics SA, Convert Pharmaceuticals SA and LivingMed Biotech srl. He received a presenter fee and/or reimbursement of travel costs/consultancy fee (in cash or in kind) from Astra Zeneca, BHV srl, and Roche. PL has/had minority shares in the companies Radiomics SA, Convert pharmaceuticals SA, Comunicare SA, LivingMed Biotech srl, and Bactam srl. PL is co-inventor of two issued patents with royalties on radiomics (PCT/NL2014/050248 and PCT/NL2014/050728), licensed to Radiomics SA; one issued patent on mtDNA (PCT/EP2014/059089), licensed to ptTheragnostic/DNAmito; one granted patent on LSRT (PCT/ P126537PC00, US patent No 12 102 842), licensed to Varian; one issued patent on Radiomic signature of hypoxia (US patent No 11 972 867), licensed to a commercial entity; one issued patent on Prodrugs (WO2019EP64112) without royalties; one non-issued, non-licensed patents on Deep Learning-Radiomics (N2024889) and three non-patented inventions (softwares) licensed to ptTheragnostic/DNAmito, Radiomics SA and Health Innovation Ventures. ARP serves as advisor for mGeneRX in exchange for equity. JM receives royalties from GE, research grants from Siemens and is unpaid consultant for Nuance. HCW owns minority shares in the company Radiomics SA. JWG serves on several radiology society AI committees. LR advises an AI startup Neurlamind. CPL is a shareholder and advisor to Bunker Hill Health, GalileoCDS, Sirona Medical, Adra, and Kheiron Medical. He serves as a board member of Bunker Hill Health and a shareholder of whiterabbit.ai. He has served as a paid consultant to Sixth Street and Gilmartin Capital. His institution has received grants or gifts from Bunker Hill Health, Carestream, CARPL, Clairity, GE Healthcare, Google Cloud, IBM, Kheiron, Lambda, Lunit, Microsoft, Philips, Siemens Healthineers, Stability.ai, Subtle Medical, VinBrain, Visiana, Whiterabbit.ai, the Lowenstein Foundation, and the Gordon and Betty Moore Foundation. GSC is a statistics editor for the BMJ and a National Institute for Health and Care Research (NIHR) Senior Investigator. The views expressed in this article are those of the author(s) and not necessarily those of the NIHR, or the Department of Health and Social Care. All other authors declare no competing interests.
C2  - PMC11795397
DA  - Feb 5
DB  - In-Process
DO  - 10.1136/bmj-2024-081554
DP  - Nlm
ET  - 20250205
L1  - internal-pdf://3829176425/FUTURE-AI_ international consensu-Lekadir-2025.pdf
LB  - 4004
N1  - Lekadir, Karim Frangi, Alejandro F Porras, Antonio R Glocker, Ben Cintas, Celia Langlotz, Curtis P Weicken, Eva Asselbergs, Folkert W Prior, Fred Collins, Gary S Kaissis, Georgios Tsakou, Gianna Buvat, Irene Kalpathy-Cramer, Jayashree Mongan, John Schnabel, Julia A Kushibar, Kaisar Riklund, Katrine Marias, Kostas Amugongo, Lameck M Fromont, Lauren A Maier-Hein, Lena Cerda-Alberich, Leonor Marti-Bonmati, Luis Cardoso, M Jorge Bobowicz, Maciej Shabani, Mahsa Tsiknakis, Manolis Zuluaga, Maria A Fritzsche, Marie-Christine Camacho, Marina Linguraru, Marius George Wenzel, Markus De Bruijne, Marleen Tolsgaard, Martin G Goisauf, Melanie Cano Abadia, Monica Papanikolaou, Nikolaos Lazrak, Noussair Pujol, Oriol Osuala, Richard Napel, Sandy Colantonio, Sara Joshi, Smriti Klein, Stefan Ausso, Susanna Rogers, Wendy A Salahuddin, Zohaib Starmans, Martijn P A eng WT_/Wellcome Trust/United Kingdom 75N92020D00021/HL/NHLBI NIH HHS/ U2R TW012131/TW/FIC NIH HHS/ England 2025/02/06 BMJ. 2025 Feb 5;388:e081554. doi: 10.1136/bmj-2024-081554.
PY  - 2025
SN  - 1756-1833 (Electronic) 0959-8138 (Print) 0959-8138 (Linking)
SP  - e081554
ST  - FUTURE-AI: international consensus guideline for trustworthy and deployable artificial intelligence in healthcare
T2  - BMJ
TI  - FUTURE-AI: international consensus guideline for trustworthy and deployable artificial intelligence in healthcare
UR  - https://www.ncbi.nlm.nih.gov/pubmed/39909534
VL  - 388
ID  - 1
ER  - 

TY  - JOUR
AB  - OBJECTIVE: To develop a domain-specific large language model (LLM) for LI-RADS v2018 categorization of hepatic observations based on free-text descriptions extracted from MRI reports. MATERIAL AND METHODS: This retrospective study included 291 small liver observations, divided into training (n = 141), validation (n = 30), and test (n = 120) datasets. Of these, 120 were fictitious, and 171 were extracted from 175 MRI reports from a single institution. The algorithm's performance was compared to two independent radiologists and one hepatologist in a human replacement scenario, and considering two combined strategies (double reading with arbitration and triage). Agreement on LI-RADS category and dichotomic malignancy (LR-4, LR-5, and LR-M) were estimated using linear-weighted κ statistics and Cohen's κ, respectively. Sensitivity and specificity for LR-5 were calculated. The consensus agreement of three other radiologists served as the ground truth. RESULTS: The model showed moderate agreement against the ground truth for both LI-RADS categorization (κ = 0.54 [95% CI: 0.42-0.65]) and the dichotomized approach (κ = 0.58 [95% CI: 0.42-0.73]). Sensitivity and specificity for LR-5 were 0.76 (95% CI: 0.69-0.86) and 0.96 (95% CI: 0.91-1.00), respectively. When the chatbot was used as a triage tool, performance improved for LI-RADS categorization (κ = 0.86/0.87 for the two independent radiologists and κ = 0.76 for the hepatologist), dichotomized malignancy (κ = 0.94/0.91 and κ = 0.87) and LR-5 identification (1.00/0.98 and 0.85 sensitivity, 0.96/0.92 and 0.92 specificity), with no statistical significance compared to the human readers' individual performance. Through this strategy, the workload decreased by 45%. CONCLUSION: LI-RADS v2018 categorization from unlabelled MRI reports is feasible using our LLM, and it enhances the efficiency of data curation. CRITICAL RELEVANCE STATEMENT: Our proof-of-concept study provides novel insights into the potential applications of LLMs, offering a real-world example of how these tools could be integrated into a local workflow to optimize data curation for research purposes. KEY POINTS: Automatic LI-RADS categorization from free-text reports would be beneficial to workflow and data mining. LiverAI, a GPT-4-based model, supported various strategies improving data curation efficiency by up to 60%. LLMs can integrate into workflows, significantly reducing radiologists' workload.
AU  - Matute-González, Mario
AU  - Darnell, Anna
AU  - Comas-Cufí, Marc
AU  - Pazó, Javier
AU  - Soler, Alexandre
AU  - Saborido, Belén
AU  - Mauro, Ezequiel
AU  - Turnes, Juan
AU  - Forner, Alejandro
AU  - Reig, María
AU  - Rimola, Jordi
DA  - 2024 Nov 22
DO  - 10.1186/s13244-024-01850-1
IS  - 1
KW  - Radiology
Natural language processing
Hepatocellular carcinoma
Report
Standardization
L1  - internal-pdf://13401/Matute-González et al. - 2024 - Utilizing a domain-specific large language model for LI-RADS v2018 categorization of free-text MRI r.pdf
LA  - eng
LB  - 2313
PY  - 2024
RN  - radiology, neurocritical_OR_"critical_care"_OR_triage_OR_emergency
SN  - 1869-4101
SP  - 280
ST  - Utilizing a domain-specific large language model for LI-RADS v2018 categorization of free-text MRI reports: a feasibility study.
T2  - Insights into imaging
TI  - Utilizing a domain-specific large language model for LI-RADS v2018 categorization of free-text MRI reports: a feasibility study
VL  - 15
ID  - 25
ER  - 

TY  - JOUR
AB  - The purposes were to assess the efficacy of AI-generated radiology reports in terms of report summary, patient-friendliness, and recommendations and to evaluate the consistent performance of report quality and accuracy, contributing to the advancement of radiology workflow. Total 685 spine MRI reports were retrieved from our hospital database. AI-generated radiology reports were generated in three formats: (1) summary reports, (2) patient-friendly reports, and (3) recommendations. The occurrence of artificial hallucinations was evaluated in the AI-generated reports. Two radiologists conducted qualitative and quantitative assessments considering the original report as a standard reference. Two non-physician raters assessed their understanding of the content of original and patient-friendly reports using a 5-point Likert scale. The scoring of the AI-generated radiology reports were overall high average scores across all three formats. The average comprehension score for the original report was 2.71 ± 0.73, while the score for the patient-friendly reports significantly increased to 4.69 ± 0.48 (p < 0.001). There were 1.12% artificial hallucinations and 7.40% potentially harmful translations. In conclusion, the potential benefits of using generative AI assistants to generate these reports include improved report quality, greater efficiency in radiology workflow for producing summaries, patient-centered reports, and recommendations, and a move toward patient-centered radiology.
AU  - Park, Jiwoo
AU  - Oh, Kangrok
AU  - Han, Kyunghwa
AU  - Lee, Young Han
DA  - 2024 Jun 8
DO  - 10.1038/s41598-024-63824-z
IS  - 1
KW  - *Artificial Intelligence
Artificial intelligence
Humans
Large language model
Female
Male
Middle Aged
Workflow
Adult
Aged
Radiology/methods
*Patient-Centered Care
Artificial hallucination
Magnetic Resonance Imaging/methods
Patient-centered radiology
Radiologic report
L1  - internal-pdf://13331/Park et al. - 2024 - Patient-centered radiology reports with generative artificial intelligence adding value to radiolog.pdf
LA  - eng
LB  - 2243
PY  - 2024
RN  - radiology
SN  - 2045-2322
SP  - 13218
ST  - Patient-centered radiology reports with generative artificial intelligence: adding value to radiology reporting.
T2  - Scientific reports
TI  - Patient-centered radiology reports with generative artificial intelligence: adding value to radiology reporting
VL  - 14
ID  - 24
ER  - 

TY  - JOUR
AB  - Large language models (LLMs) hold transformative potential for medical image labeling in radiology, addressing challenges posed by linguistic variability in reports. We developed a two-stage natural language processing pipeline that combines Bidirectional Encoder Representations from Transformers (BERT) and an LLM to analyze radiology reports. In the first stage (Entity Key Classification), BERT model identifies and classifies clinically relevant entities mentioned in the text. In the second stage (Relationship Mapping), the extracted entities are incorporated into the LLM to infer relationships between entity pairs, considering actual presence of entity. The pipeline targets lesion-location mapping in chest CT and diagnosis-episode mapping in brain MRI, both of which are clinically important for structuring radiologic findings and capturing temporal patterns of disease progression. Using over 400,000 reports from Seoul Asan Medical Center, our pipeline achieved a macro F1-score of 77.39 for chest CT and 70.58 for brain MRI. These results highlight the effectiveness of integrating BERT with an LLM to enhance diagnostic accuracy in radiology report analysis.
AU  - Shin, Chaiho
AU  - Eom, Dareen
AU  - Lee, Sang Min
AU  - Park, Ji Eun
AU  - Kim, Kwangsoo
AU  - Lee, Kye Hwa
DA  - 2025/08/27/
DO  - 10.1038/s41598-025-16213-z
IS  - 1
J2  - Sci Rep
KW  - Humans
Large Language Models
*Natural Language Processing
Brain/diagnostic imaging
Language
Magnetic Resonance Imaging
Tomography, X-Ray Computed
L1  - internal-pdf://0446340713/Two stage large language model appro-Shin-2025.pdf
LA  - eng
LB  - 2584
PY  - 2025
RN  - CT, brain, radiology
SN  - 2045-2322
SP  - 31550
ST  - Two stage large language model approach enhancing entity classification and relationship mapping in radiology reports
T2  - Scientific reports
TI  - Two stage large language model approach enhancing entity classification and relationship mapping in radiology reports
VL  - 15
ID  - 19
ER  - 

TY  - JOUR
AB  - Large language models (LLMs) possess a range of capabilities which may be applied to the clinical domain, including text summarization. As ambient artificial intelligence scribes and other LLM-based tools begin to be deployed within healthcare settings, rigorous evaluations of the accuracy of these technologies are urgently needed. In this cross-sectional study of 100 randomly sampled adult Emergency Department (ED) visits from 2012 to 2023 at the University of California, San Francisco ED, we sought to investigate the performance of GPT-4 and GPT-3.5-turbo in generating ED encounter summaries and evaluate the prevalence and type of errors for each section of the encounter summary across three evaluation criteria: 1) Inaccuracy of LLM-summarized information; 2) Hallucination of information; 3) Omission of relevant clinical information. In total, 33% of summaries generated by GPT-4 and 10% of those generated by GPT-3.5-turbo were entirely error-free across all evaluated domains. Summaries generated by GPT-4 were mostly accurate, with inaccuracies found in only 10% of cases, however, 42% of the summaries exhibited hallucinations and 47% omitted clinically relevant information. Inaccuracies and hallucinations were most commonly found in the Plan sections of LLM-generated summaries, while clinical omissions were concentrated in text describing patients' Physical Examination findings or History of Presenting Complaint. The potential harmfulness score across errors was low, with a mean score of 0.57 (SD 1.11) out of 7 and only three errors scoring 4 ('Potential for permanent harm') or greater. In summary, we found that LLMs could generate accurate encounter summaries but were liable to hallucination and omission of clinically relevant information. Individual errors on average had a low potential for harm. A comprehensive understanding of the location and type of errors found in LLM-generated clinical text is important to facilitate clinician review of such content and prevent patient harm.
AU  - Williams, Christopher Y. K.
AU  - Bains, Jaskaran
AU  - Tang, Tianyu
AU  - Patel, Kishan
AU  - Lucas, Alexa N.
AU  - Chen, Fiona
AU  - Miao, Brenda Y.
AU  - Butte, Atul J.
AU  - Kornblith, Aaron E.
DA  - 2025 Jun
DO  - 10.1371/journal.pdig.0000899
IS  - 6
L1  - internal-pdf://13048/Williams et al. - 2025 - Evaluating large language models for drafting emergency department encounter summaries..pdf
LA  - eng
LB  - 1985
PY  - 2025
RN  - clinical, neurocritical_OR_"critical_care"_OR_triage_OR_emergency
SN  - 2767-3170
SP  - e0000899
ST  - Evaluating large language models for drafting emergency department encounter summaries.
T2  - PLOS digital health
TI  - Evaluating large language models for drafting emergency department encounter summaries
VL  - 4
ID  - 36
ER  - 

TY  - JOUR
AB  - IMPORTANCE: High-quality discharge summaries are associated with improved patient outcomes, but contribute to clinical documentation burden. Large language models (LLMs) provide an opportunity to support physicians by drafting discharge summary narratives. OBJECTIVE: To determine whether LLM-generated discharge summary narratives are of comparable quality and safety to those of physicians. DESIGN, SETTING, AND PARTICIPANTS: This cross-sectional study conducted at the University of California, San Francisco included 100 randomly selected inpatient hospital medicine encounters of 3 to 6 days' duration between 2019 and 2022. The analysis took place in July 2024. EXPOSURE: A blinded evaluation of physician- and LLM-generated narratives was performed in duplicate by 22 attending physician reviewers. MAIN OUTCOMES AND MEASURES: Narratives were reviewed for overall quality, reviewer preference, comprehensiveness, concision, coherence, and 3 error types (inaccuracies, omissions, and hallucinations). Each error individually, and each narrative overall, were assigned potential harmfulness scores ranging from 0 to 7 on an adapted Agency for Healthcare Research and Quality scale. RESULTS: Across 100 encounters, LLM- and physician-generated narratives were comparable in overall quality on a Likert scale ranging from 1 to 5 (higher scores indicate higher quality; mean [SD] score, 3.67 [0.49] vs 3.77 [0.57]; P = .21) and reviewer preference (χ2 = 5.2; P = .27). LLM-generated narratives were more concise (mean [SD] score, 4.01 [0.37] vs 3.70 [0.59]; P < .001) and more coherent (mean [SD] score, 4.16 [0.39] vs 4.01 [0.53]; P = .02) than their physician-generated counterparts, but less comprehensive (mean [SD] score, 3.72 [0.58] vs 4.13 [0.58]; P < .001). LLM-generated narratives contained more unique errors (mean [SD] errors per summary, 2.91 [2.54]) than physician-generated narratives (mean [SD] errors per summary, 1.82 [1.94]). There was no significant difference in the potential for harm between LLM- and physician-generated narratives across individual errors (mean [SD] of 1.35 [1.07] vs 1.34 [1.05]; P = .99), with 6 and 5 individual errors, respectively, with scores of 4 (potential for permanent harm) or greater. Both LLM- and physician-generated narratives had low overall potential for harm (scores <1 on a scale ranging from 0-7), with LLM-generated narratives scoring higher than physician narratives (mean [SD] score of 0.84 [0.98] vs 0.36 [0.70]; P < .001) and only 1 LLM-generated narrative (compared with 0 physician-generated narratives) scoring 4 or greater. CONCLUSIONS AND RELEVANCE: In this cross-sectional study of 100 inpatient hospital medicine encounters, LLM-generated discharge summary narratives were of comparable quality, and were preferred equally, to those generated by physicians. LLM-generated narratives were more likely to contain errors but had low overall harmfulness scores. These results suggest that, in clinical practice, using such narratives after human review may provide a viable option for hospitalists.
AU  - Williams, Christopher Y. K.
AU  - Subramanian, Charumathi Raghu
AU  - Ali, Syed Salman
AU  - Apolinario, Michael
AU  - Askin, Elisabeth
AU  - Barish, Peter
AU  - Cheng, Monica
AU  - Deardorff, W. James
AU  - Donthi, Nisha
AU  - Ganeshan, Smitha
AU  - Huang, Owen
AU  - Kantor, Molly A.
AU  - Lai, Andrew R.
AU  - Manchanda, Ashley
AU  - Moore, Kendra A.
AU  - Muniyappa, Anoop N.
AU  - Nair, Geethu
AU  - Patel, Prashant P.
AU  - Santhosh, Lekshmi
AU  - Schneider, Susan
AU  - Torres, Shawn
AU  - Yukawa, Michi
AU  - Hubbard, Colin C.
AU  - Rosner, Benjamin I.
DA  - 2025 Jul 1
DO  - 10.1001/jamainternmed.2025.0821
IS  - 7
KW  - Humans
Large Language Models
*Language
Female
Male
Middle Aged
*Electronic Health Records
Cross-Sectional Studies
*Physicians
*Narration
*Patient Discharge Summaries/standards
*Patient Discharge
San Francisco
LA  - eng
LB  - 604
PY  - 2025
RN  - clinical
SN  - 2168-6114 2168-6106
SP  - 818–825
ST  - Physician- and Large Language Model-Generated Hospital Discharge Summaries.
T2  - JAMA internal medicine
TI  - Physician- and Large Language Model-Generated Hospital Discharge Summaries
UR  - https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2833228
VL  - 185
ID  - 12
ER  - 

TY  - JOUR
AB  - BACKGROUND: Large language models (LLMs) show increasing potential for their use in healthcare for administrative support and clinical decision making. However, reports on their performance in critical care medicine is lacking. METHODS: This study evaluated five LLMs (GPT-4o, GPT-4o-mini, GPT-3.5-turbo, Mistral Large 2407 and Llama 3.1 70B) on 1181 multiple choice questions (MCQs) from the gotheextramile.com database, a comprehensive database of critical care questions at European Diploma in Intensive Care examination level. Their performance was compared to random guessing and 350 human physicians on a 77-MCQ practice test. Metrics included accuracy, consistency, and domain-specific performance. Costs, as a proxy for energy consumption, were also analyzed. RESULTS: GPT-4o achieved the highest accuracy at 93.3%, followed by Llama 3.1 70B (87.5%), Mistral Large 2407 (87.9%), GPT-4o-mini (83.0%), and GPT-3.5-turbo (72.7%). Random guessing yielded 41.5% (p < 0.001). On the practice test, all models surpassed human physicians, scoring 89.0%, 80.9%, 84.4%, 80.3%, and 66.5%, respectively, compared to 42.7% for random guessing (p < 0.001) and 61.9% for the human physicians. However, in contrast to the other evaluated LLMs (p < 0.001), GPT-3.5-turbo's performance did not significantly outperform physicians (p = 0.196). Despite high overall consistency, all models gave consistently incorrect answers. The most expensive model was GPT-4o, costing over 25 times more than the least expensive model, GPT-4o-mini. CONCLUSIONS: LLMs exhibit exceptional accuracy and consistency, with four outperforming human physicians on a European-level practice exam. GPT-4o led in performance but raised concerns about energy consumption. Despite their potential in critical care, all models produced consistently incorrect answers, highlighting the need for more thorough and ongoing evaluations to guide responsible implementation in clinical settings.
AU  - Workum, Jessica D.
AU  - Volkers, Bas W. S.
AU  - van de Sande, Davy
AU  - Arora, Sumesh
AU  - Goeijenbier, Marco
AU  - Gommers, Diederik
AU  - van Genderen, Michel E.
DA  - 2025 Feb 10
DO  - 10.1186/s13054-025-05302-0
IS  - 1
KW  - Humans
Large Language Models
Large language models
Generative artificial intelligence
Critical care
Surveys and Questionnaires
*Benchmarking/methods/standards
*Critical Care/methods/standards
Benchmarking
L1  - internal-pdf://13053/Workum et al. - 2025 - Comparative evaluation and performance of large language models on expert level critical care questi.pdf
LA  - eng
LB  - 1990
PY  - 2025
RN  - clinical, neurocritical_OR_"critical_care"_OR_triage_OR_emergency
SN  - 1466-609X 1364-8535
SP  - 72
ST  - Comparative evaluation and performance of large language models on expert level critical care questions: a benchmark study.
T2  - Critical care (London, England)
TI  - Comparative evaluation and performance of large language models on expert level critical care questions: a benchmark study
VL  - 29
ID  - 37
ER  - 

TY  - JOUR
AB  - BACKGROUND: For medical diagnosis, clinicians typically begin with a patient's chief concerns, followed by questions about symptoms and medical history, physical examinations, and requests for necessary auxiliary examinations to gather comprehensive medical information. This complex medical investigation process has yet to be modeled by existing artificial intelligence (AI) methodologies. OBJECTIVE: The aim of this study was to develop an AI-driven medical inquiry assistant for clinical diagnosis that provides inquiry recommendations by simulating clinicians' medical investigating logic via reinforcement learning. METHODS: We compiled multicenter, deidentified outpatient electronic health records from 76 hospitals in Shenzhen, China, spanning the period from July to November 2021. These records consisted of both unstructured textual information and structured laboratory test results. We first performed feature extraction and standardization using natural language processing techniques and then used a reinforcement learning actor-critic framework to explore the rational and effective inquiry logic. To align the inquiry process with actual clinical practice, we segmented the inquiry into 4 stages: inquiring about symptoms and medical history, conducting physical examinations, requesting auxiliary examinations, and terminating the inquiry with a diagnosis. External validation was conducted to validate the inquiry logic of the AI model. RESULTS: This study focused on 2 retrospective inquiry-and-diagnosis tasks in the emergency and pediatrics departments. The emergency departments provided records of 339,020 consultations including mainly children (median age 5.2, IQR 2.6-26.1 years) with various types of upper respiratory tract infections (250,638/339,020, 73.93%). The pediatrics department provided records of 561,659 consultations, mainly of children (median age 3.8, IQR 2.0-5.7 years) with various types of upper respiratory tract infections (498,408/561,659, 88.73%). When conducting its own inquiries in both scenarios, the AI model demonstrated high diagnostic performance, with areas under the receiver operating characteristic curve of 0.955 (95% CI 0.953-0.956) and 0.943 (95% CI 0.941-0.944), respectively. When the AI model was used in a simulated collaboration with physicians, it notably reduced the average number of physicians' inquiries to 46% (6.037/13.26; 95% CI 6.009-6.064) and 43% (6.245/14.364; 95% CI 6.225-6.269) while achieving areas under the receiver operating characteristic curve of 0.972 (95% CI 0.970-0.973) and 0.968 (95% CI 0.967-0.969) in the scenarios. External validation revealed a normalized Kendall τ distance of 0.323 (95% CI 0.301-0.346), indicating the inquiry consistency of the AI model with physicians. CONCLUSIONS: This retrospective analysis of predominantly respiratory pediatric presentations in emergency and pediatrics departments demonstrated that an AI-driven diagnostic assistant had high diagnostic performance both in stand-alone use and in simulated collaboration with clinicians. Its investigation process was found to be consistent with the clinicians' medical investigation logic. These findings highlight the diagnostic assistant's promise in assisting the decision-making processes of health care professionals.
AU  - Zou, Xuan
AU  - He, Weijie
AU  - Huang, Yu
AU  - Ouyang, Yi
AU  - Zhang, Zhen
AU  - Wu, Yu
AU  - Wu, Yongsheng
AU  - Feng, Lili
AU  - Wu, Sheng
AU  - Yang, Mengqi
AU  - Chen, Xuyan
AU  - Zheng, Yefeng
AU  - Jiang, Rui
AU  - Chen, Ting
DA  - 2024 Aug 23
DO  - 10.2196/54616
KW  - artificial intelligence
natural language processing
*Artificial Intelligence
Humans
Retrospective Studies
*Electronic Health Records/statistics & numerical data
electronic health record
China
Algorithms
reinforcement learning
Emergency Service, Hospital/statistics & numerical data
inquiry and diagnosis
L1  - internal-pdf://0719885380/AI-Driven Diagnostic Assistance in Me-Zou-2024.pdf internal-pdf://2044897756/AI-Driven Diagnostic Assistance in Me-Zou-2021.pdf
LA  - eng
LB  - 2674
PY  - 2024
RN  - clinical, neurocritical_OR_"critical_care"_OR_triage_OR_emergency
SN  - 1438-8871 1439-4456
SP  - e54616
ST  - AI-Driven Diagnostic Assistance in Medical Inquiry: Reinforcement Learning Algorithm Development and Validation.
T2  - Journal of medical Internet research
TI  - AI-Driven Diagnostic Assistance in Medical Inquiry: Reinforcement Learning Algorithm Development and Validation
VL  - 26
ID  - 38
ER  - 

